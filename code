import pandas as pd
import numpy as np
import seaborn as sns
import os
%matplotlib inline

import matplotlib.pyplot as plt
import matplotlib.pyplot as plotter
from sklearn.model_selection import cross_val_score
from sklearn import metrics
from sklearn.base import BaseEstimator, TransformerMixin, ClassifierMixin, clone
from sklearn.model_selection import KFold
from scipy import stats
from scipy.stats import norm, skew
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, accuracy_score
from sklearn.feature_selection import SelectFromModel
import warnings
warnings.filterwarnings('ignore')

train = pd.read_csv('Traffic.csv')
train

train, test = train_test_split(train,test_size=0.1,random_state=1992)
print("Shape of train: ",train.shape)
print("Shape of test",test.shape)

train.isnull().sum()

test.isnull().sum()

print('train')
display(train.info())
print('test')
display(test.info())

sns.histplot(train,x='Time',hue='Traffic Situation',kde=True)

sns.histplot(train,x='Day of the week',hue='Traffic Situation',kde=True)

sns.histplot(train,x='CarCount',hue='Traffic Situation',kde=True)

sns.histplot(train,x='BikeCount',hue='Traffic Situation',kde=True)

sns.histplot(train,x='BusCount',hue='Traffic Situation',kde=True)

sns.histplot(train,x='TruckCount',hue='Traffic Situation',kde=True)

sns.histplot(train,x='Total',hue='Traffic Situation',kde=True)

plt.subplot(1, 3, 1)
sns.countplot(x = train["Day of the week"])
plotter.xticks(rotation = 90);

plt.subplot(1, 3, 3)
sns.countplot(x = train["Traffic Situation"])
plotter.xticks(rotation = 90);
plt.show()

df_temp=train
df_temp['Day of the week'] = df_temp['Day of the week'].replace({'Monday':1,'Tuesday':2,'Wednesday':3,'Thursday':4,'Friday':5,'Saturday': 6,'Sunday':7})
df_temp['Traffic Situation'] = df_temp['Traffic Situation'].replace({'low': 0,'normal': 1,'high': 2, 'heavy':3})
train=df_temp
train

train_temp=train

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
train_temp['Time'] = le.fit_transform(train_temp['Time'])

corr = train_temp.corr(method='pearson')
fig, ax = plt.subplots(figsize=(20, 20))
sns.heatmap(corr, cmap='RdBu', annot=True, fmt=".2f")
plt.xticks(range(len(corr.columns)), corr.columns);
plt.yticks(range(len(corr.columns)), corr.columns)
plt.show()

train = train.drop(columns=["Day of the week"],axis=1)
train

X= train.drop(columns=["Traffic Situation"],axis=1)
y= train["Traffic Situation"]
X_train=X
y_train=y
from sklearn.preprocessing import StandardScaler
StandardScaler = StandardScaler()
X_train = StandardScaler.fit_transform(X_train)
X_train = pd.DataFrame(X_train)
X_train

data.columns

import pandas as pd
from sklearn.model_selection import train_test_split

# Load data from CSV
data = pd.read_csv("Traffic.csv")
# Split the data into features and target variable
X = data.drop(columns=['Traffic Situation'])
y = data['Traffic Situation']
# Split data into training and testing sets (adjust test_size and random_state as needed)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Optionally, you can save the split datasets to new CSV files
X_train.to_csv("train_data.csv", index=False)
X_test.to_csv("test_data.csv", index=False)
y_train.to_csv("train_target.csv", index=False)
y_test.to_csv("test_target.csv", index=False)

# Alternatively, if you want to keep the datasets in memory, you can just print their shapes
print("Training data shape:", X_train.shape)
print("Testing data shape:", X_test.shape)
print("Training target shape:", y_train.shape)
print("Testing target shape:", y_test.shape)

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder

# Encode categorical variables
label_encoder_day = LabelEncoder()
data['Day of the week'] = label_encoder_day.fit_transform(data['Day of the week'])

label_encoder_traffic = LabelEncoder()
data['Traffic Situation'] = label_encoder_traffic.fit_transform(data['Traffic Situation'])

# Select features and target
X = data[['Time', 'Day of the week', 'CarCount', 'BikeCount', 'BusCount', 'TruckCount', 'Total']]
y = data['Traffic Situation']

# Convert 'Time' to a numerical value (e.g., minutes since midnight)
X['Time'] = pd.to_datetime(X['Time'], format='%I:%M:%S %p').dt.hour * 60 + pd.to_datetime(X['Time'], format='%I:%M:%S %p').dt.minute

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

X_train.head(), y_train.head()

from sklearn.model_selection import cross_val_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier

# Initialize the classifiers
knn = KNeighborsClassifier()
rf = RandomForestClassifier()

# Cross-validation
cv_scores_knn = cross_val_score(knn, X_train, y_train, cv=5)
cv_scores_rf = cross_val_score(rf, X_train, y_train, cv=5)

# Create a DataFrame to display the results
results = pd.DataFrame({
    'Classifier': ['KNN', 'Random Forest'],
    'CV Mean Accuracy': [np.mean(cv_scores_knn), np.mean(cv_scores_rf)],
    'CV Std Dev': [np.std(cv_scores_knn), np.std(cv_scores_rf)]
})

print(results)

import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split

# Preprocessing (example: filling missing values, normalizing)
data.fillna(method='ffill', inplace=True)

# Assume 'Traffic' is the column we want to predict
traffic_data = data['Total'].values.reshape(-1, 1)

# Normalize the data
scaler = MinMaxScaler()
traffic_data_scaled = scaler.fit_transform(traffic_data)

def create_sequences(data, seq_length):
    xs, ys = [], []
    for i in range(len(data) - seq_length):
        x = data[i:i+seq_length]
        y = data[i+seq_length]
        xs.append(x)
        ys.append(y)
    return np.array(xs), np.array(ys)

seq_length = 50  # example sequence length
X, y = create_sequences(traffic_data_scaled, seq_length)

# Split into training and testing datasets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier

le = LabelEncoder()
data['Traffic Situation'] = le.fit_transform(data['Traffic Situation'])

features = data[['CarCount', 'BikeCount', 'BusCount', 'TruckCount', 'Total']]
target = data['Traffic Situation']

X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3, random_state=42)

knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(X_train, y_train)
y_pred_knn = knn.predict(X_test)

from sklearn.neighbors import KNeighborsClassifier

# Initialize the model
model = KNeighborsClassifier (n_neighbors = 5)

# Fit the model
model.fit(X_test, y_test)

acc = model.score(X_train, y_train)

acc

from sklearn.ensemble import RandomForestClassifier
rfc = RandomForestClassifier()
rfc.fit(X_train, y_train)

rfc_pred = rfc.predict(X_test)
accuracy = accuracy_score(y_test, rfc_pred)
accuracy

cm_knn = confusion_matrix(y_test, y_pred_knn)
cm_rf = confusion_matrix(y_test, y_pred_rf)

fig, axes = plt.subplots(1, 2, figsize=(12, 5))

sns.heatmap(cm_knn, annot=True, fmt='d', cmap='Blues', ax=axes[0])
axes[0].set_title('KNN Confusion Matrix')
axes[0].set_xlabel('Predicted')
axes[0].set_ylabel('Actual')

sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Blues', ax=axes[1])
axes[1].set_title('Random Forest Confusion Matrix')
axes[1].set_xlabel('Predicted')
axes[1].set_ylabel('Actual')

plt.tight_layout()
plt.show()

from sklearn.metrics import precision_score, recall_score, accuracy_score

# Calculate precision, recall, and accuracy for KNN
knn_precision = precision_score(y_test, y_pred_knn, average='weighted')
knn_recall = recall_score(y_test, y_pred_knn, average='weighted')
knn_accuracy = accuracy_score(y_test, y_pred_knn)

# Calculate precision, recall, and accuracy for Random Forest
rf_precision = precision_score(y_test, y_pred_rf, average='weighted')
rf_recall = recall_score(y_test, y_pred_rf, average='weighted')
rf_accuracy = accuracy_score(y_test, y_pred_rf)

results = pd.DataFrame({
    'Classifier': ['KNN', 'Random Forest'],
    'Precision': [knn_precision, rf_precision],
    'Recall': [knn_recall, rf_recall],
    'Accuracy': [knn_accuracy, rf_accuracy]
})

print(results)
